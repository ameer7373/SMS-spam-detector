{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMYrG63kbg3t3avi/TVj4MV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameer7373/SMS-spam-detector/blob/main/Smsspamdec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB0M0b6--y-O"
      },
      "outputs": [],
      "source": [
        "pip install pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "Szlh3Zdz_RKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/spam.csv.csv\",encoding='latin-1')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mHgZPHPK_U4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TOqiNm6wDAf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
        "df = df.rename(columns={'v1':'label','v2':'Text'})\n",
        "df['label_enc'] = df['label'].map({'ham':0,'spam':1})\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "yh2jqMuy_7Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U4XkMZjhFnZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oy1uIS07AMgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6a1XyDefANbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKdgSMIMAOnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.countplot(x=df['label'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BtaQvftkABZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_words_len=round(sum([len(i.split()) for i in df['Text']])/len(df['Text']))\n",
        "print(avg_words_len)"
      ],
      "metadata": {
        "id": "Q_h67Sk8APz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding Total no of unique words in corpus\n",
        "s = set()\n",
        "for sent in df['Text']:\n",
        "  for word in sent.split():\n",
        "\t   s.add(word)\n",
        "total_words_length=len(s)\n",
        "print(total_words_length)\n"
      ],
      "metadata": {
        "id": "Kd6FeEdLAYku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data for Training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = np.asanyarray(df['Text']), np.asanyarray(df['label_enc'])\n",
        "new_df = pd.DataFrame({'Text': X, 'label': y})\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "\tnew_df['Text'], new_df['label'], test_size=0.2, random_state=42)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "jtv4VJj1Apz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7E2bh_oeAsSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "\n",
        "tfidf_vec = TfidfVectorizer().fit(X_train)\n",
        "X_train_vec,X_test_vec = tfidf_vec.transform(X_train),tfidf_vec.transform(X_test)\n",
        "\n",
        "baseline_model = MultinomialNB()\n",
        "baseline_model.fit(X_train_vec,y_train)\n"
      ],
      "metadata": {
        "id": "wwPe2XRDAv79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "MAXTOKENS=total_words_length\n",
        "OUTPUTLEN=avg_words_len\n",
        "\n",
        "text_vec = TextVectorization(\n",
        "\tmax_tokens=MAXTOKENS,\n",
        "\tstandardize='lower_and_strip_punctuation',\n",
        "\toutput_mode='int',\n",
        "\toutput_sequence_length=OUTPUTLEN\n",
        ")\n",
        "text_vec.adapt(X_train)\n"
      ],
      "metadata": {
        "id": "ChSVb3UCAzOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "\tinput_dim=MAXTOKENS,\n",
        "\toutput_dim=128,\n",
        "\tembeddings_initializer='uniform',\n",
        "\tinput_length=OUTPUTLEN\n",
        ")\n"
      ],
      "metadata": {
        "id": "aPlWgsIZA5V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = layers.Input(shape=(1,), dtype=tf.string)\n",
        "vec_layer = text_vec(input_layer)\n",
        "embedding_layer_model = embedding_layer(vec_layer)\n",
        "x = layers.GlobalAveragePooling1D()(embedding_layer_model)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_1 = keras.Model(input_layer, output_layer)\n",
        "\n",
        "model_1.compile(optimizer='adam', loss=keras.losses.BinaryCrossentropy(\n",
        "\tlabel_smoothing=0.5), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "PEu2aBVsA-_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "id": "xnfFLwJ4BEid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = np.asanyarray(df['Text']), np.asanyarray(df['label_enc'])\n",
        "new_df = pd.DataFrame({'Text': X, 'label': y})\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    new_df['Text'], new_df['label'], test_size=0.2, random_state=42)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "YOqcA_JLCZE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "\n",
        "tfidf_vec = TfidfVectorizer().fit(X_train)\n",
        "X_train_vec,X_test_vec = tfidf_vec.transform(X_train),tfidf_vec.transform(X_test)\n",
        "\n",
        "baseline_model = MultinomialNB()\n",
        "baseline_model.fit(X_train_vec,y_train)\n"
      ],
      "metadata": {
        "id": "1RIkw8ktDCXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rCMzITclDRJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "MAXTOKENS=total_words_length\n",
        "OUTPUTLEN=avg_words_len\n",
        "\n",
        "text_vec = TextVectorization(\n",
        "\tmax_tokens=MAXTOKENS,\n",
        "\tstandardize='lower_and_strip_punctuation',\n",
        "\toutput_mode='int',\n",
        "\toutput_sequence_length=OUTPUTLEN\n",
        ")\n",
        "text_vec.adapt(X_train)\n"
      ],
      "metadata": {
        "id": "vWYkPAAeDViS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4X3DjGvBeCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "\tinput_dim=MAXTOKENS,\n",
        "\toutput_dim=128,\n",
        "\tembeddings_initializer='uniform',\n",
        "\tinput_length=OUTPUTLEN\n",
        ")\n"
      ],
      "metadata": {
        "id": "uS30f4GsDkQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = layers.Input(shape=(1,), dtype=tf.string)\n",
        "vec_layer = text_vec(input_layer)\n",
        "embedding_layer_model = embedding_layer(vec_layer)\n",
        "x = layers.GlobalAveragePooling1D()(embedding_layer_model)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_1 = keras.Model(input_layer, output_layer)\n",
        "\n",
        "model_1.compile(optimizer='adam', loss=keras.losses.BinaryCrossentropy(\n",
        "\tlabel_smoothing=0.5), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "3dJEBbA_DmF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def compile_model(model):\n",
        "\t'''\n",
        "\tsimply compile the model with adam optimzer\n",
        "\t'''\n",
        "\tmodel.compile(optimizer=keras.optimizers.Adam(),\n",
        "\t\t\t\tloss=keras.losses.BinaryCrossentropy(),\n",
        "\t\t\t\tmetrics=['accuracy'])\n",
        "\n",
        "def fit_model(model, epochs, X_train=X_train, y_train=y_train,\n",
        "\t\t\tX_test=X_test, y_test=y_test):\n",
        "\t'''\n",
        "\tfit the model with given epochs, train\n",
        "\tand test data\n",
        "\t'''\n",
        "\thistory = model.fit(X_train,\n",
        "\t\t\t\t\t\ty_train,\n",
        "\t\t\t\t\t\tepochs=epochs,\n",
        "\t\t\t\t\t\tvalidation_data=(X_test, y_test),\n",
        "\t\t\t\t\t\tvalidation_steps=int(0.2*len(X_test)))\n",
        "\treturn history\n",
        "\n",
        "def evaluate_model(model, X, y):\n",
        "\t'''\n",
        "\tevaluate the model and returns accuracy,\n",
        "\tprecision, recall and f1-score\n",
        "\t'''\n",
        "\ty_preds = np.round(model.predict(X))\n",
        "\taccuracy = accuracy_score(y, y_preds)\n",
        "\tprecision = precision_score(y, y_preds)\n",
        "\trecall = recall_score(y, y_preds)\n",
        "\tf1 = f1_score(y, y_preds)\n",
        "\n",
        "\tmodel_results_dict = {'accuracy': accuracy,\n",
        "\t\t\t\t\t\t'precision': precision,\n",
        "\t\t\t\t\t\t'recall': recall,\n",
        "\t\t\t\t\t\t'f1-score': f1}\n",
        "\n",
        "\treturn model_results_dict\n"
      ],
      "metadata": {
        "id": "58AIbHmzDwLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = layers.Input(shape=(1,), dtype=tf.string)\n",
        "vec_layer = text_vec(input_layer)\n",
        "embedding_layer_model = embedding_layer(vec_layer)\n",
        "bi_lstm = layers.Bidirectional(layers.LSTM(\n",
        "\t64, activation='tanh', return_sequences=True))(embedding_layer_model)\n",
        "lstm = layers.Bidirectional(layers.LSTM(64))(bi_lstm)\n",
        "flatten = layers.Flatten()(lstm)\n",
        "dropout = layers.Dropout(.1)(flatten)\n",
        "x = layers.Dense(32, activation='relu')(dropout)\n",
        "output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = keras.Model(input_layer, output_layer)\n",
        "\n",
        "compile_model(model_2) # compile the model\n",
        "history_2 = fit_model(model_2, epochs=5) # fit the model\n"
      ],
      "metadata": {
        "id": "SzTUElI6DyhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# model with Sequential api\n",
        "model_3 = keras.Sequential()\n",
        "\n",
        "# universal-sentence-encoder layer\n",
        "# directly from tfhub\n",
        "use_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "\t\t\t\t\t\ttrainable=False,\n",
        "\t\t\t\t\t\tinput_shape=[],\n",
        "\t\t\t\t\t\tdtype=tf.string,\n",
        "\t\t\t\t\t\tname='USE')\n",
        "model_3.add(use_layer)\n",
        "model_3.add(layers.Dropout(0.2))\n",
        "model_3.add(layers.Dense(64, activation=keras.activations.relu))\n",
        "model_3.add(layers.Dense(1, activation=keras.activations.sigmoid))\n",
        "\n",
        "compile_model(model_3)\n",
        "\n",
        "history_3 = fit_model(model_3, epochs=5)\n"
      ],
      "metadata": {
        "id": "b64ob7LDD3Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model_results = evaluate_model(baseline_model, X_test_vec, y_test)\n",
        "model_1_results = evaluate_model(model_1, X_test, y_test)\n",
        "model_2_results = evaluate_model(model_2, X_test, y_test)\n",
        "model_3_results = evaluate_model(model_3, X_test, y_test)\n",
        "\n",
        "total_results = pd.DataFrame({'MultinomialNB Model':baseline_model_results,\n",
        "\t\t\t\t\t\t\t'Custom-Vec-Embedding Model':model_1_results,\n",
        "\t\t\t\t\t\t\t'Bidirectional-LSTM Model':model_2_results,\n",
        "\t\t\t\t\t\t\t'USE-Transfer learning Model':model_3_results}).transpose()\n",
        "\n",
        "total_results\n"
      ],
      "metadata": {
        "id": "6QqXpiO8EmZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kg7XYrVLFAIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_results)"
      ],
      "metadata": {
        "id": "VP48MX8YFAPY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}